{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hacker News](https://en.wikipedia.org/wiki/Hacker_News) is a social news website focusing on computer science and entrepreneurship. The word hacker in \"Hacker News\" is used in its original meaning and refers to the hacker culture which consists of people who enjoy tinkering with technology. This project looks into the posts on the Hacker News website.\n",
    "\n",
    "The purpose of this project is to answer the following:\n",
    "\n",
    "1. Determine which type of post, 'Ask HN' or 'Show HN', recieves more comments.\n",
    "2. Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gfulham\\Dataquest_JPNBs\\1_intro_exercises\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '1.1_Basics_Project.ipynb',\n",
       " '1.2 Intermediate Basics Hacker News.ipynb',\n",
       " 'HN_posts_year_to_Sep_26_2016.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data as a list of lists instead of a df. Only since beginner course and working with lists\n",
    "file = open(\"HN_posts_year_to_Sep_26_2016.csv\", encoding=\"utf8\") # Had to specify because of coding error. \n",
    "hn = list(csv.reader(file))\n",
    "hn[:5] #Quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12579008',\n",
       "  'You have two days to comment if you want stem cells to be classified as your own',\n",
       "  'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018',\n",
       "  '1',\n",
       "  '0',\n",
       "  'altstar',\n",
       "  '9/26/2016 3:26'],\n",
       " ['12579005',\n",
       "  'SQLAR  the SQLite Archiver',\n",
       "  'https://www.sqlite.org/sqlar/doc/trunk/README.md',\n",
       "  '1',\n",
       "  '0',\n",
       "  'blacksqr',\n",
       "  '9/26/2016 3:24'],\n",
       " ['12578997',\n",
       "  'What if we just printed a flatscreen television on the side of our boxes?',\n",
       "  'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43',\n",
       "  '1',\n",
       "  '0',\n",
       "  'pavel_lishin',\n",
       "  '9/26/2016 3:19'],\n",
       " ['12578989',\n",
       "  'algorithmic music',\n",
       "  'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext',\n",
       "  '1',\n",
       "  '0',\n",
       "  'poindontcare',\n",
       "  '9/26/2016 3:16'],\n",
       " ['12578979',\n",
       "  'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake',\n",
       "  'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94',\n",
       "  '1',\n",
       "  '0',\n",
       "  'markgainor1',\n",
       "  '9/26/2016 3:14']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get header row\n",
    "headers = hn[0]\n",
    "print(headers) # Looking at the header variable\n",
    "hn = hn[1:] # Removing the header from the dataset\n",
    "hn[:5] #Making sure the dataset has the header removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "#Create 3 lists outside the loop\n",
    "ask_hn = []\n",
    "show_hn = []\n",
    "other_hn = []\n",
    "\n",
    "#loop through rows in hn\n",
    "for each in hn:\n",
    "    title = each[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_hn.append(each)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_hn.append(each)\n",
    "    else:\n",
    "        other_hn.append(each)\n",
    "\n",
    "#Check length of each list\n",
    "print(len(ask_hn))\n",
    "print(len(show_hn))\n",
    "print(len(other_hn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN Total comments=  94986\n",
      "Ask HN Average comments= 10.393478498741656\n",
      "Show HN Total comments =  49633\n",
      "Show HN Average comments = 4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "#Find the total and average amount of comments for the Ask_hn and Show_hn lists. \n",
    "\n",
    "#Find total comments for ask_hn\n",
    "total_ask_comments = 0\n",
    "for each in ask_hn:\n",
    "    comment_count = int(each[4])\n",
    "    total_ask_comments += comment_count\n",
    "\n",
    "#Find total commments for show_hn\n",
    "total_show_comments = 0\n",
    "for each in show_hn:\n",
    "    comment_count = int(each[4])\n",
    "    total_show_comments += comment_count\n",
    "    \n",
    "#Find avg comments\n",
    "avg_ask_comments = total_ask_comments / len(ask_hn)\n",
    "avg_show_comments = total_show_comments / len(show_hn)\n",
    "\n",
    "print('Ask HN Total comments= ', total_ask_comments)\n",
    "print('Ask HN Average comments= {}'.format(avg_ask_comments))\n",
    "print('Show HN Total comments = ', total_show_comments)\n",
    "print('Show HN Average comments = {}'.format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data shows there are overall more comments on 'Ask HN' posts, as well as more comments on average from these posts. <br>\n",
    "Now lets examine if there is a specific time of day that these posts receive more comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9/26/2016 2:53', 7], ['9/26/2016 1:17', 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'02': 2996,\n",
       " '01': 2089,\n",
       " '22': 3372,\n",
       " '21': 4500,\n",
       " '19': 3954,\n",
       " '17': 5547,\n",
       " '15': 18525,\n",
       " '14': 4972,\n",
       " '13': 7245,\n",
       " '11': 2797,\n",
       " '10': 3013,\n",
       " '09': 1477,\n",
       " '07': 1585,\n",
       " '03': 2154,\n",
       " '23': 2297,\n",
       " '20': 4462,\n",
       " '16': 4466,\n",
       " '08': 2362,\n",
       " '00': 2277,\n",
       " '18': 4877,\n",
       " '12': 4234,\n",
       " '04': 2360,\n",
       " '06': 1587,\n",
       " '05': 1838}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the ask posts grouped by each hour of the day \n",
    "#Avg the ask posts grouped by each hour of the day\n",
    "#Use datetime.strptime()\n",
    "ask_hn[:1]\n",
    "import datetime as dt \n",
    "result_list = []\n",
    "#iterate ask_posts and append result_list with num comments\n",
    "for each in ask_hn:\n",
    "    created_at = each[6]\n",
    "    num_comments = int(each[4])\n",
    "    \n",
    "    result_list.append([created_at,num_comments])\n",
    "    \n",
    "print(result_list[:2])\n",
    "    \n",
    "#create two dictionaries posts_by_hour and comments_by_hour\n",
    "posts_by_hour = {} #To see at what time posts are posted, grouped by hour of the day\n",
    "comments_by_hour = {} #To see how many comments are posted on posts grouped by the hour of the day posted\n",
    "date_format = '%m/%d/%Y %H:%M'\n",
    "    \n",
    "#loop through result_list and extract the hour from the date, being the first element of the row\n",
    "for each in result_list:\n",
    "    date = each[0] #put date-string into a variable\n",
    "    comment = each[1] \n",
    "    hour = dt.datetime.strptime(date, date_format).strftime('%H') #strip the hour from the string\n",
    "    if hour not in posts_by_hour:\n",
    "        posts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "    else: \n",
    "        posts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment\n",
    "\n",
    "\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Avg Num of Comments on Posts by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['02', 11.137546468401487],\n",
       " ['01', 7.407801418439717],\n",
       " ['22', 8.804177545691905],\n",
       " ['21', 8.687258687258687],\n",
       " ['19', 7.163043478260869],\n",
       " ['17', 9.449744463373083],\n",
       " ['15', 28.676470588235293],\n",
       " ['14', 9.692007797270955],\n",
       " ['13', 16.31756756756757],\n",
       " ['11', 8.96474358974359],\n",
       " ['10', 10.684397163120567],\n",
       " ['09', 6.653153153153153],\n",
       " ['07', 7.013274336283186],\n",
       " ['03', 7.948339483394834],\n",
       " ['23', 6.696793002915452],\n",
       " ['20', 8.749019607843136],\n",
       " ['16', 7.713298791018998],\n",
       " ['08', 9.190661478599221],\n",
       " ['00', 7.5647840531561465],\n",
       " ['18', 7.94299674267101],\n",
       " ['12', 12.380116959064328],\n",
       " ['04', 9.7119341563786],\n",
       " ['06', 6.782051282051282],\n",
       " ['05', 8.794258373205741]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty list to store the avgerages\n",
    "avg_by_hour = []\n",
    "\n",
    "#Loop over comments_by_hour list. Append the key(hour) and the value(total_comments)/value(total posts) \n",
    "for each in comments_by_hour:\n",
    "    avg_by_hour.append([each,comments_by_hour[each] / posts_by_hour[each]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.676470588235293, '15']\n",
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00:28.68 average comments per post.\n",
      "13:00:16.32 average comments per post.\n",
      "12:00:12.38 average comments per post.\n",
      "02:00:11.14 average comments per post.\n",
      "10:00:10.68 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for each in avg_by_hour:\n",
    "    swap_avg_by_hour.append([each[1],each[0]])\n",
    "\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(sorted_swap[0])\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "     print('{}:{:.2f} average comments per post.'.format(dt.datetime.strptime(hr,'%H').strftime('%H:%M'),avg))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that receives the most comments per post on average in 15:00 with an average of 23.68 comments per post. According the to [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home) this translates to 3:00 PM EST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataquest_env",
   "language": "python",
   "name": "dataquest_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
